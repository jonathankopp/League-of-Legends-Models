{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "from matplotlib import pyplot\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from time import localtime\n",
    "from datetime import datetime as dt\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.spatial.distance import cdist\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('NN_Data/preproDataFull.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGDIR = './graphs'\n",
    "sess    = tf.Session()\n",
    "\n",
    "# HYPER PARAMS\n",
    "LEARN   = 0.01\n",
    "BATCH   = 950\n",
    "EPOCHS  = 10\n",
    "\n",
    "# HIDDEN LAYERS\n",
    "HL_1    = 10\n",
    "HL_2    = 2\n",
    "\n",
    "\n",
    "# SPLIT TRAIN AND TEST\n",
    "Train, Test = train_test_split(df.copy(),test_size=.1,random_state=22)\n",
    "\n",
    "# OTHER PARAMS\n",
    "INPUT_S = Train.shape[1] - 1\n",
    "N_CLASS = 950"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "    \n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 \n",
      "=========\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (950,) for Tensor 'input_29/labels:0', which has shape '(?, 950)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-0c68c1748c3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mbatch_xs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_Train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_Train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0msummary_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msummary_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mgames\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_xs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_ys\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mtrain_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 950\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1147\u001b[0m                              \u001b[0;34m'which has shape %r'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m                              (np_val.shape, subfeed_t.name,\n\u001b[0;32m-> 1149\u001b[0;31m                               str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m   1150\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (950,) for Tensor 'input_29/labels:0', which has shape '(?, 950)'"
     ]
    }
   ],
   "source": [
    "with tf.name_scope('input'):\n",
    "    games  = tf.placeholder(tf.float32, [None,INPUT_S], name='games')\n",
    "    labels = tf.placeholder(tf.float32, [None,N_CLASS], name='labels')\n",
    "def fc_layer(x,layer,size_out,activation=None):\n",
    "    with tf.name_scope(layer):\n",
    "        size_in   = int(x.shape[1])\n",
    "        W         = tf.Variable(tf.random_normal([size_in,size_out]), name='weights')\n",
    "        b         = tf.Variable(tf.constant(-1, dtype=tf.float32, shape=[size_out]), name='biases')\n",
    "        \n",
    "        wx_plus_b = tf.add(tf.matmul(x, W), b)\n",
    "        if activation:\n",
    "            return activation(wx_plus_b)\n",
    "        return wx_plus_b\n",
    "# layer inits\n",
    "fc_1 = fc_layer(games, 'fc_1', HL_1, tf.nn.relu)\n",
    "fc_2 = fc_layer(fc_1, 'fc_2', HL_2, tf.nn.relu)\n",
    "\n",
    "# to prevent overfit\n",
    "dropp = tf.nn.dropout(fc_2, keep_prob=0.9)\n",
    "y     = fc_layer(dropp, 'output', N_CLASS)\n",
    "with tf.name_scope('loss'): \n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y,labels=labels))\n",
    "    tf.summary.scalar('loss',loss)\n",
    "    \n",
    "with tf.name_scope('optimizer'):   \n",
    "    train = tf.train.AdamOptimizer(LEARN).minimize(loss)\n",
    "    \n",
    "    \n",
    "with tf.name_scope('evaluation'):    \n",
    "    correct  = tf.equal(tf.argmax(y,1), tf.argmax(labels,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct,dtype=tf.float32))\n",
    "    tf.summary.scalar('accuracy',accuracy)\n",
    "train_writer = tf.summary.FileWriter(os.path.join(LOGDIR, \"train\"), sess.graph)\n",
    "test_writer  = tf.summary.FileWriter(os.path.join(LOGDIR, \"test\"), sess.graph)\n",
    "\n",
    "\n",
    "summary_op   = tf.summary.merge_all()\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "with tf.name_scope('training'):    \n",
    "    step = 0\n",
    "    for epoch in range(EPOCHS):\n",
    "        print('epoch',epoch,\"\\n=========\\n\")\n",
    "        \n",
    "        for batch in range(int(Train.shape[0]/BATCH)):\n",
    "            step+=1\n",
    "            \n",
    "            Y_Train = np.array(list(Train['res']))\n",
    "            Y_Test  = np.array(list(Test['res']))\n",
    "            \n",
    "            X_Train = Train.drop(['res'],axis=1).copy()\n",
    "            X_Test  = Test.drop(['res'],axis=1).copy()\n",
    "            \n",
    "            X_Train = X_Train.to_numpy()\n",
    "            X_Test  = X_Test.to_numpy()\n",
    "            \n",
    "            batch_xs, batch_ys = next_batch(BATCH,X_Train,Y_Train)\n",
    "            \n",
    "            summary_result, _ = sess.run( [summary_op, train], feed_dict={games: batch_xs, labels: batch_ys} )\n",
    "\n",
    "            train_writer.add_summary(summary_result, step)\n",
    "            summary_result, acc = sess.run( [summary_op, accuracy], feed_dict={games: X_Test, labels: Y_Test} )\n",
    "\n",
    "            test_writer.add_summary(summary_result, step)\n",
    "\n",
    "            print(\"Batch \", batch, \": accuracy = \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
