{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inputify(fileName):\n",
    "    return fileName\n",
    "def outputify(fileName):\n",
    "    return fileName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "from matplotlib import pyplot\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from time import localtime\n",
    "from datetime import datetime as dt\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.spatial.distance import cdist\n",
    "from pathlib import Path\n",
    "\n",
    "working_directory     = str(os.getcwd()) + \"/\"\n",
    "# working_directoryPT = str(Path.home()) + \"/\"\n",
    "# wd                  = \"/Users/Jonat/Dropbox/CreateDawg/ImRight/input/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "\n",
    "def hyperTune(model,X_Train,Y_Train,X_Test,Y_Test):\n",
    "    #Hyperparameter find utilizing grid search cross validation \n",
    "    C = [1, 10, 100, 1000]\n",
    "    mItr = [500]\n",
    "    tol = [.001,.01]\n",
    "#     class_weight = [{'Blue':0.5, 'Red':0.5}, {'Blue':0.4, 'Red':0.6}, {'Blue':0.6, 'Red':0.4}, {'Blue':0.7, 'Red':0.3},'none']\n",
    "    solver = ['newton-cg', 'lbfgs','sag','saga']\n",
    "    param_grid = dict(tol=tol,max_iter=mItr, C=C,  solver=solver)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    grid = GridSearchCV(estimator=model,param_grid=param_grid,cv=cv,scoring='roc_auc',verbose=1,n_jobs=-1)\n",
    "    grid_result = grid.fit(X_Train, Y_Train)\n",
    "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "    for mean, stdev, param in zip(means, stds, params):\n",
    "        print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "#     print(\"========================================================\")\n",
    "#     print('Train Score: ', grid_result.best_score_)\n",
    "#     print('Best Train Params: ', grid_result.best_params_)\n",
    "#     # print('Validation score:',grid.score(X_Val,Y_Val))\n",
    "#     print('Test score:',grid.score(X_Test,Y_Test))\n",
    "# #     return grid_result.best_params_\n",
    "    return grid_result.best_params_ , grid.score(X_Test, Y_Test)\n",
    "def hyperTuneXGB(model,X_Train,Y_Train,X_Test,Y_Test):\n",
    "    #Hyperparameter find utilizing grid search cross validation \n",
    "    params = {\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'alpha': [0.0001, 0.05,0.1],\n",
    "        'max_depth': [3, 4, 5]\n",
    "    }\n",
    "#     cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    grid = GridSearchCV(estimator=model,param_grid=params,cv=5,scoring='roc_auc',verbose=1,n_jobs=-1)\n",
    "    grid_result = grid.fit(X_Train, Y_Train)\n",
    "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "    for mean, stdev, param in zip(means, stds, params):\n",
    "        print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    return grid_result.best_params_ , grid.score(X_Test, Y_Test)\n",
    "def hyperTuneSVC(model,X_Train,Y_Train,X_Test,Y_Test):\n",
    "    #Hyperparameter find utilizing grid search cross validation \n",
    "    params = {'C': [0.1, 1, 10, 100, 1000],  \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "              'kernel': ['linear','poly','rbf','sigmoid']}  \n",
    "#     cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    grid = GridSearchCV(estimator=model,param_grid=params,cv=5,scoring='roc_auc',verbose=1,n_jobs=-1)\n",
    "    grid_result = grid.fit(X_Train, Y_Train)\n",
    "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "    for mean, stdev, param in zip(means, stds, params):\n",
    "        print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    return grid_result.best_params_ , grid.score(X_Test, Y_Test)\n",
    "def hyperTuneRF(model,X_Train,Y_Train,X_Test,Y_Test):\n",
    "    # Number of trees in random forest\n",
    "    n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "    # Number of features to consider at every split\n",
    "    max_features = ['auto', 'sqrt']\n",
    "    # Maximum number of levels in tree\n",
    "    max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "    max_depth.append(None)\n",
    "    # Minimum number of samples required to split a node\n",
    "    min_samples_split = [2, 5, 10]\n",
    "    # Minimum number of samples required at each leaf node\n",
    "    min_samples_leaf = [1, 2, 4]\n",
    "    # Method of selecting samples for training each tree\n",
    "    bootstrap = [True, False]\n",
    "    # Create the random grid\n",
    "    params    = {'n_estimators': n_estimators,'max_features': max_features,'max_depth': max_depth,'min_samples_split': min_samples_split,'min_samples_leaf': min_samples_leaf,'bootstrap': bootstrap}\n",
    "    grid = GridSearchCV(estimator=model,param_grid=params,cv=5,scoring='roc_auc',verbose=1,n_jobs=-1)\n",
    "    grid_result = grid.fit(X_Train, Y_Train)\n",
    "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "    for mean, stdev, param in zip(means, stds, params):\n",
    "        print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    return grid_result.best_params_ , grid.score(X_Test, Y_Test)\n",
    "def hyperTuneMLP(model,X_Train,Y_Train,X_Test,Y_Test):\n",
    "    #Hyperparameter find utilizing grid search cross validation \n",
    "    parameter_space = {\n",
    "    'hidden_layer_sizes': [(72,),(107,),(107,214,107),(107,50,20)],\n",
    "    'activation': ['tanh', 'relu','logistic'],\n",
    "    'solver': ['sgd', 'adam','lbfgs'],\n",
    "    'alpha': [0.0001, 0.05,0.1],\n",
    "    'learning_rate': ['constant','adaptive','invscaling'],\n",
    "    }\n",
    "#     cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    grid = GridSearchCV(estimator=model,param_grid=parameter_space,cv=5,scoring='roc_auc',verbose=1,n_jobs=-1)\n",
    "    grid_result = grid.fit(X_Train, Y_Train)\n",
    "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "    for mean, stdev, param in zip(means, stds, params):\n",
    "        print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "#     print(\"========================================================\")\n",
    "#     print('Train Score: ', grid_result.best_score_)\n",
    "#     print('Best Train Params: ', grid_result.best_params_)\n",
    "#     # print('Validation score:',grid.score(X_Val,Y_Val))\n",
    "#     print('Test score:',grid.score(X_Test,Y_Test))\n",
    "# #     return grid_result.best_params_\n",
    "    return grid_result.best_params_ , grid.score(X_Test, Y_Test)\n",
    "def gnb(X_Train,Y_Train,X_Test,Y_Test):\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    clf    = GaussianNB()\n",
    "    clf.fit(X_Train,Y_Train)\n",
    "    y_pred = clf.predict(X_Test)\n",
    "    acc    = accuracy_score(Y_Test,y_pred)\n",
    "    return clf, acc\n",
    "def mlp(X_Train,Y_Train,X_Test,Y_Test):\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    from sklearn.metrics import accuracy_score\n",
    "#     {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (72,), 'learning_rate': 'invscaling', 'solver': 'adam'}\n",
    "#   {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (107, 214, 107), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
    "    clf = MLPClassifier(max_iter=10000,activation= 'tanh', alpha= 0.0001,tol=.001, hidden_layer_sizes= (107, 214, 107), learning_rate= 'adaptive', solver= 'adam')\n",
    "    clf.fit(X_Train,Y_Train)\n",
    "    y_pred = clf.predict(X_Test)\n",
    "    acc    = accuracy_score(Y_Test,y_pred)\n",
    "    return clf, acc\n",
    "#     clf = MLPClassifier(max_iter=1)\n",
    "\n",
    "#     hyperparams, bestScore = hyperTuneMLP(clf,X_Train,Y_Train,X_Test,Y_Test)\n",
    "#     return hyperparams, bestScore\n",
    "    \n",
    "def rforest(X_Train,Y_Train,X_Test,Y_Test):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.metrics import accuracy_score\n",
    "#     clf = RandomForestClassifier()\n",
    "#     clf.fit(X_Train,Y_Train)\n",
    "#     y_pred = clf.predict(X_Test)\n",
    "#     acc    = accuracy_score(Y_Test,y_pred)\n",
    "#     #     ,classification_report(Y_Test, predictions)\n",
    "#     return clf, acc\n",
    "\n",
    "    clf = RandomForestClassifier()\n",
    "    hyperparams, bestScore = hyperTuneRF(clf,X_Train,Y_Train,X_Test,Y_Test)\n",
    "    return hyperparams, bestScore\n",
    "\n",
    "def boosted(X_Train,Y_Train,X_Test,Y_Test):\n",
    "    from xgboost import XGBClassifier\n",
    "    from sklearn.metrics import accuracy_score\n",
    "#     {'alpha': 0.05, 'colsample_bytree': 1.0, 'gamma': 5, 'max_depth': 3, 'min_child_weight': 10, 'subsample': 1.0}\n",
    "    boost    = XGBClassifier(booster='gbtree',alpha='.05',colsample_bytree =1.0, gamma = 5, max_depth = 3, min_child_weight = 10, subsample= 1.0)\n",
    "    boost.fit(X_Train,Y_Train)\n",
    "    y_pred   = boost.predict(X_Test)\n",
    "    accuracy = accuracy_score(Y_Test,y_pred)\n",
    "#     ,classification_report(Y_Test, predictions)\n",
    "    return boost, accuracy\n",
    "\n",
    "#     boost = XGBClassifier()\n",
    "#     hyperparams, bestScore = hyperTuneXGB(boost,X_Train,Y_Train,X_Test,Y_Test)\n",
    "#     return hyperparams, bestScore\n",
    "def boosted2(X_Train,Y_Train,X_Test,Y_Test):\n",
    "    from xgboost import XGBClassifier\n",
    "    from sklearn.metrics import accuracy_score\n",
    "#     {'alpha': 0.05, 'colsample_bytree': 1.0, 'gamma': 5, 'max_depth': 3, 'min_child_weight': 10, 'subsample': 1.0}\n",
    "    boost    = XGBClassifier(alpha = 0.1, colsample_bytree = 1.0, gamma = 5, max_depth = 3, min_child_weight = 10, subsample = 1.0)\n",
    "    boost.fit(X_Train,Y_Train)\n",
    "    y_pred   = boost.predict(X_Test)\n",
    "    accuracy = accuracy_score(Y_Test,y_pred)\n",
    "#     ,classification_report(Y_Test, predictions)\n",
    "    return boost, accuracy,classification_report(Y_Test, y_pred)\n",
    "\n",
    "#     boost = XGBClassifier()\n",
    "#     hyperparams, bestScore = hyperTuneXGB(boost,X_Train,Y_Train,X_Test,Y_Test)\n",
    "#     return hyperparams, bestScore\n",
    "def svc(X_Train,Y_Train,X_Test,Y_Test):\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.metrics import accuracy_score\n",
    "#     {'alpha': 0.05, 'colsample_bytree': 1.0, 'gamma': 5, 'max_depth': 3, 'min_child_weight': 10, 'subsample': 1.0}\n",
    "#     C = 100, gamma = 0.0001, kernel = 'rbf'\n",
    "    svc    = SVC(C = 1, gamma = 0.1, kernel = 'sigmoid',probability=True)\n",
    "    svc.fit(X_Train,Y_Train)\n",
    "    y_pred   = svc.predict(X_Test)\n",
    "    accuracy = accuracy_score(Y_Test,y_pred)\n",
    "#     ,classification_report(Y_Test, y_pred)\n",
    "    return svc, accuracy, classification_report(Y_Test, y_pred)\n",
    "#     svc = SVC()\n",
    "#     hyperparams, bestScore = hyperTuneSVC(svc,X_Train,Y_Train,X_Test,Y_Test)\n",
    "#     return hyperparams, bestScore\n",
    "def logReg(X_Train,Y_Train,X_Test,Y_Test):\n",
    "#     {'C': 1000, 'max_iter': 500, 'solver': 'newton-cg', 'tol': 0.001}\n",
    "#    {'C': 1000, 'max_iter': 500, 'solver': 'newton-cg', 'tol': 0.001}\n",
    "#     logRegg = LogisticRegression(class_weight = 'none', max_iter= 10000, tol = 0.001, solver= 'newton-cg')\n",
    "#     logRegg.fit(X_Train,Y_Train)\n",
    "#     # model   = SelectFromModel(logRegg,prefit=True)\n",
    "#     # x_new   = model.transform(X_Train)\n",
    "#     # chopp   = model.get_support()\n",
    "#     # for i in range(len(Headers)):\n",
    "#     # if(chopp[i]==True):\n",
    "#     # # print(Headers[i])\n",
    "#     print(\"G: \"+g+\" Score: \",logRegg.score(X_Test,Y_Test))\n",
    "#     return logRegg, logRegg.score(X_Test,Y_Test)\n",
    "#     print(\"================================================================\")\n",
    "\n",
    "    # feature selection\n",
    "\n",
    "#     logRegg = LogisticRegression()\n",
    "#     # get the hyperparameters\n",
    "#     try:\n",
    "#         hyperparams, bestScore = hyperTune(logRegg,X_Train,Y_Train,X_Test,Y_Test)\n",
    "#         return hyperparams, bestScore\n",
    "#     except ValueError:\n",
    "#         print('lolwut')\n",
    "    logRegg = LogisticRegression(C = 10, max_iter = 500, solver = 'sag', tol = 0.01,random_state = 42)\n",
    "    logRegg.fit(X_Train,Y_Train)\n",
    "    predictions = logRegg.predict(X_Test) \n",
    "#     ,classification_report(Y_Test, predictions)\n",
    "    return logRegg, logRegg.score(X_Test,Y_Test),classification_report(Y_Test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13095, 47) (2619, 36)\n"
     ]
    }
   ],
   "source": [
    "fPM        = pd.read_csv('LCS_Data/playerMatchUps.csv')\n",
    "fOD        = pd.read_csv('LCS_Data/objectiveData.csv')\n",
    "gameAmount = len(list(set(list(fPM['gamenum']))))\n",
    "print(fPM.shape, fOD.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data for stacks\n",
    "fPM_1 = fPM[fPM['gamenum']<(gameAmount/2)].copy()\n",
    "fOD_1 = fOD[fOD['gamenum']<(gameAmount/2)].copy()\n",
    "fPM_2 = fPM[fPM['gamenum']>(gameAmount/2)].copy()\n",
    "fOD_2 = fOD[fOD['gamenum']>(gameAmount/2)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PVP Results:\n",
      "top 0.4961832061068702\n",
      "jng 0.5648854961832062\n",
      "mid 0.5725190839694656\n",
      "bot 0.6183206106870229\n",
      "sup 0.648854961832061\n",
      "\n",
      "Objective Acc: 0.6335877862595419\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/mnt/c/Users/Jonat/Dropbox/CreateDawg/3SC/scalers_LCS/sObj_2.pkl']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ========================================== first layer ======================================== #\n",
    "\n",
    "# ***************************  pvp model  ******************************\n",
    "print('PVP Results:')\n",
    "positions = ['top','jng','mid','bot','sup']\n",
    "for pos in positions:\n",
    "    relevantD   = fPM_1[fPM_1['position'] == pos].copy() \n",
    "    relevantD.drop(['gamenum','position'],axis=1,inplace=True)\n",
    "    # pvp matchup model creation\n",
    "    train, test = train_test_split(relevantD.copy(),test_size=.1,random_state=33)\n",
    "    # test, val   = train_test_split(test.copy(),test_size=.5)\n",
    "    y_train     = train['res']\n",
    "    y_test      = test['res']\n",
    "    # y_val       = val['res']\n",
    "    train.drop(['res'],axis=1,inplace=True)\n",
    "    test.drop(['res'],axis=1,inplace=True)\n",
    "    # val.drop(['res'],axis=1,inplace=True)\n",
    "\n",
    "    scalersPVP = Normalizer()\n",
    "    train   = scalersPVP.fit_transform(train)\n",
    "    test    = scalersPVP.transform(test)\n",
    "    \n",
    "    modelPVP,scorePVP = boosted(train,y_train,test,y_test)\n",
    "    print(pos,scorePVP)\n",
    "    joblib.dump(modelPVP,outputify(working_directory+\"pvpModels_LCS/\"+pos+\"_2.pkl\"))\n",
    "    joblib.dump(scalersPVP,outputify(working_directory+\"scalers_LCS/\"+pos+\"_scaler_2.pkl\"))\n",
    "\n",
    "\n",
    "    \n",
    "print()\n",
    "# *****************************  objective model **************************\n",
    "relevantD_OD   = fOD_1.copy() \n",
    "relevantD_OD.drop(['gamenum'],axis=1,inplace=True)\n",
    "# pvp matchup model creation\n",
    "train, test = train_test_split(relevantD_OD.copy(),test_size=.1,random_state=34)\n",
    "# test, val   = train_test_split(test.copy(),test_size=.5)\n",
    "y_train     = train['res']\n",
    "y_test      = test['res']\n",
    "# y_val       = val['res']\n",
    "train.drop(['res'],axis=1,inplace=True)\n",
    "test.drop(['res'],axis=1,inplace=True)\n",
    "# val.drop(['res'],axis=1,inplace=True)\n",
    "\n",
    "scalersO = Normalizer()\n",
    "train   = scalersO.fit_transform(train)\n",
    "test    = scalersO.transform(test)\n",
    "\n",
    "modelO,scoreO = logReg(train,y_train,test,y_test)[:2]\n",
    "print(\"Objective Acc:\",scoreO)\n",
    "\n",
    "\n",
    "joblib.dump(modelO,outputify(working_directory+\"objectiveModels_LCS/obj_2.pkl\"))\n",
    "joblib.dump(scalersO,outputify(working_directory+\"scalers_LCS/sObj_2.pkl\"))\n",
    "# =================================== end of first layer ======================================== #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================ Creating The Stacked Dataset ========================================\n",
    "stackedTbl  = []\n",
    "results     = list(fOD_2['res'])\n",
    "gameNumbers = sorted(list(set(list(fPM_2['gamenum']))))\n",
    "\n",
    "modelObj    = joblib.load(\"objectiveModels_LCS/obj_2.pkl\")\n",
    "scalerObj   = joblib.load(\"scalers_LCS/sObj_2.pkl\")\n",
    "for game in gameNumbers:\n",
    "    teamR = []\n",
    "    teamB = []\n",
    "    gameDataPVP = fPM_2[fPM_2['gamenum']==game].copy()\n",
    "    gameDataObj = fOD_2[fOD_2['gamenum']==game].copy()\n",
    "    for pos in positions:\n",
    "        relevantD = gameDataPVP[gameDataPVP['position']==pos].copy()\n",
    "        relevantD.drop(['res','position','gamenum'],inplace=True,axis=1)\n",
    "        \n",
    "        relevantM = joblib.load(\"pvpModels_LCS/\"+pos+\"_2.pkl\")\n",
    "        relevantS = joblib.load(\"scalers_LCS/\"+pos+\"_scaler_2.pkl\")\n",
    "        \n",
    "        scaledRD  = relevantS.transform(relevantD)\n",
    "        pvpProbs  = relevantM.predict_proba(scaledRD)\n",
    "        teamR.append(pvpProbs[0][0])\n",
    "        teamB.append(pvpProbs[0][1])\n",
    "    gameDataObj.drop(['res','gamenum'],inplace=True,axis=1)\n",
    "    scaledObjData = scalerObj.transform(gameDataObj)\n",
    "#     objResult = modelObj.predict(scaledObjData)\n",
    "#     teamR.append(objResult[0])\n",
    "    teamB.append(results[game-(len(gameNumbers)+2)])\n",
    "    stackedTbl.append(teamR + teamB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================ Turning Dataset to DataFrame ===============================\n",
    "rl = []\n",
    "bl = []\n",
    "for pos in positions:\n",
    "    rl.append(\"r_\"+pos+'_pred')\n",
    "    bl.append(\"b_\"+pos+'_pred')\n",
    "\n",
    "\n",
    "stackedDF = pd.DataFrame(data=stackedTbl, columns = rl + bl + ['res'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r_top_pred</th>\n",
       "      <th>r_jng_pred</th>\n",
       "      <th>r_mid_pred</th>\n",
       "      <th>r_bot_pred</th>\n",
       "      <th>r_sup_pred</th>\n",
       "      <th>b_top_pred</th>\n",
       "      <th>b_jng_pred</th>\n",
       "      <th>b_mid_pred</th>\n",
       "      <th>b_bot_pred</th>\n",
       "      <th>b_sup_pred</th>\n",
       "      <th>res</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.229288</td>\n",
       "      <td>0.347382</td>\n",
       "      <td>0.541006</td>\n",
       "      <td>0.255425</td>\n",
       "      <td>0.370808</td>\n",
       "      <td>0.770712</td>\n",
       "      <td>0.652618</td>\n",
       "      <td>0.458994</td>\n",
       "      <td>0.744575</td>\n",
       "      <td>0.629192</td>\n",
       "      <td>Red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.498902</td>\n",
       "      <td>0.544089</td>\n",
       "      <td>0.700473</td>\n",
       "      <td>0.462837</td>\n",
       "      <td>0.477297</td>\n",
       "      <td>0.501098</td>\n",
       "      <td>0.455911</td>\n",
       "      <td>0.299527</td>\n",
       "      <td>0.537163</td>\n",
       "      <td>0.522703</td>\n",
       "      <td>Red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.716532</td>\n",
       "      <td>0.550678</td>\n",
       "      <td>0.451387</td>\n",
       "      <td>0.657487</td>\n",
       "      <td>0.562952</td>\n",
       "      <td>0.283468</td>\n",
       "      <td>0.449322</td>\n",
       "      <td>0.548613</td>\n",
       "      <td>0.342513</td>\n",
       "      <td>0.437048</td>\n",
       "      <td>Blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.594227</td>\n",
       "      <td>0.487469</td>\n",
       "      <td>0.595188</td>\n",
       "      <td>0.384470</td>\n",
       "      <td>0.400474</td>\n",
       "      <td>0.405773</td>\n",
       "      <td>0.512531</td>\n",
       "      <td>0.404812</td>\n",
       "      <td>0.615530</td>\n",
       "      <td>0.599526</td>\n",
       "      <td>Red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.547326</td>\n",
       "      <td>0.452280</td>\n",
       "      <td>0.752299</td>\n",
       "      <td>0.631427</td>\n",
       "      <td>0.724823</td>\n",
       "      <td>0.452674</td>\n",
       "      <td>0.547720</td>\n",
       "      <td>0.247701</td>\n",
       "      <td>0.368573</td>\n",
       "      <td>0.275177</td>\n",
       "      <td>Red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>0.449654</td>\n",
       "      <td>0.490735</td>\n",
       "      <td>0.242664</td>\n",
       "      <td>0.765376</td>\n",
       "      <td>0.631457</td>\n",
       "      <td>0.550346</td>\n",
       "      <td>0.509265</td>\n",
       "      <td>0.757336</td>\n",
       "      <td>0.234624</td>\n",
       "      <td>0.368543</td>\n",
       "      <td>Blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>0.665877</td>\n",
       "      <td>0.432098</td>\n",
       "      <td>0.460776</td>\n",
       "      <td>0.573173</td>\n",
       "      <td>0.784947</td>\n",
       "      <td>0.334123</td>\n",
       "      <td>0.567902</td>\n",
       "      <td>0.539224</td>\n",
       "      <td>0.426827</td>\n",
       "      <td>0.215053</td>\n",
       "      <td>Blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>0.399761</td>\n",
       "      <td>0.346567</td>\n",
       "      <td>0.250220</td>\n",
       "      <td>0.380518</td>\n",
       "      <td>0.388476</td>\n",
       "      <td>0.600239</td>\n",
       "      <td>0.653433</td>\n",
       "      <td>0.749780</td>\n",
       "      <td>0.619482</td>\n",
       "      <td>0.611524</td>\n",
       "      <td>Blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>0.708655</td>\n",
       "      <td>0.467761</td>\n",
       "      <td>0.710266</td>\n",
       "      <td>0.668272</td>\n",
       "      <td>0.618710</td>\n",
       "      <td>0.291345</td>\n",
       "      <td>0.532239</td>\n",
       "      <td>0.289734</td>\n",
       "      <td>0.331728</td>\n",
       "      <td>0.381290</td>\n",
       "      <td>Blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>0.459947</td>\n",
       "      <td>0.488327</td>\n",
       "      <td>0.563364</td>\n",
       "      <td>0.497923</td>\n",
       "      <td>0.422301</td>\n",
       "      <td>0.540053</td>\n",
       "      <td>0.511673</td>\n",
       "      <td>0.436636</td>\n",
       "      <td>0.502077</td>\n",
       "      <td>0.577699</td>\n",
       "      <td>Red</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1309 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      r_top_pred  r_jng_pred  r_mid_pred  r_bot_pred  r_sup_pred  b_top_pred  \\\n",
       "0       0.229288    0.347382    0.541006    0.255425    0.370808    0.770712   \n",
       "1       0.498902    0.544089    0.700473    0.462837    0.477297    0.501098   \n",
       "2       0.716532    0.550678    0.451387    0.657487    0.562952    0.283468   \n",
       "3       0.594227    0.487469    0.595188    0.384470    0.400474    0.405773   \n",
       "4       0.547326    0.452280    0.752299    0.631427    0.724823    0.452674   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "1304    0.449654    0.490735    0.242664    0.765376    0.631457    0.550346   \n",
       "1305    0.665877    0.432098    0.460776    0.573173    0.784947    0.334123   \n",
       "1306    0.399761    0.346567    0.250220    0.380518    0.388476    0.600239   \n",
       "1307    0.708655    0.467761    0.710266    0.668272    0.618710    0.291345   \n",
       "1308    0.459947    0.488327    0.563364    0.497923    0.422301    0.540053   \n",
       "\n",
       "      b_jng_pred  b_mid_pred  b_bot_pred  b_sup_pred   res  \n",
       "0       0.652618    0.458994    0.744575    0.629192   Red  \n",
       "1       0.455911    0.299527    0.537163    0.522703   Red  \n",
       "2       0.449322    0.548613    0.342513    0.437048  Blue  \n",
       "3       0.512531    0.404812    0.615530    0.599526   Red  \n",
       "4       0.547720    0.247701    0.368573    0.275177   Red  \n",
       "...          ...         ...         ...         ...   ...  \n",
       "1304    0.509265    0.757336    0.234624    0.368543  Blue  \n",
       "1305    0.567902    0.539224    0.426827    0.215053  Blue  \n",
       "1306    0.653433    0.749780    0.619482    0.611524  Blue  \n",
       "1307    0.532239    0.289734    0.331728    0.381290  Blue  \n",
       "1308    0.511673    0.436636    0.502077    0.577699   Red  \n",
       "\n",
       "[1309 rows x 11 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"LCS_Data/moesStack_3.csv\",\"w\",newline='\\n') as f:\n",
    "    stackedDF.to_csv(f,index=False,sep=',',header=True)\n",
    "stackedDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================== bottom layer ======================================== #\n",
    "best = 0\n",
    "bScore = -999\n",
    "scores = []\n",
    "for i in range(1000):\n",
    "    tempData = stackedDF.copy()\n",
    "#     tempData.obj_pred.replace(('Red', 'Blue'), (0, 1), inplace=True)\n",
    "    train, test = train_test_split(tempData.copy(),test_size=.1,random_state=i)\n",
    "    # test, val   = train_test_split(test.copy(),test_size=.5)\n",
    "    y_train     = train['res']\n",
    "    y_test      = test['res']\n",
    "    # y_val       = val['res']\n",
    "    train.drop(['res'],axis=1,inplace=True)\n",
    "    test.drop(['res'],axis=1,inplace=True)\n",
    "    # val.drop(['res'],axis=1,inplace=True)\n",
    "\n",
    "    scalers = Normalizer()\n",
    "    train   = scalers.fit_transform(train)\n",
    "    test    = scalers.transform(test)\n",
    "\n",
    "    model,score = boosted2(train,y_train,test,y_test)[:2]\n",
    "    scores.append(score)\n",
    "    if(score>bScore):\n",
    "        bScore=score\n",
    "        best=i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Blue       0.55      0.35      0.43        51\n",
      "         Red       0.66      0.81      0.73        80\n",
      "\n",
      "    accuracy                           0.63       131\n",
      "   macro avg       0.60      0.58      0.58       131\n",
      "weighted avg       0.62      0.63      0.61       131\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tempData = stackedDF.copy()\n",
    "# tempData.obj_pred.replace(('Red', 'Blue'), (0, 1), inplace=True)\n",
    "train, test = train_test_split(tempData.copy(),test_size=.1,random_state=best)\n",
    "# test, val   = train_test_split(test.copy(),test_size=.5)\n",
    "y_train     = train['res']\n",
    "y_test      = test['res']\n",
    "# y_val       = val['res']\n",
    "train.drop(['res'],axis=1,inplace=True)\n",
    "test.drop(['res'],axis=1,inplace=True)\n",
    "# val.drop(['res'],axis=1,inplace=True)\n",
    "\n",
    "scalers = Normalizer()\n",
    "train   = scalers.fit_transform(train)\n",
    "test    = scalers.transform(test)\n",
    "\n",
    "# model,score = logReg(train,y_train,test,y_test)\n",
    "# print(score)\n",
    "model = boosted2(train,y_train,test,y_test)[0]\n",
    "print(boosted2(train,y_train,test,y_test)[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5190839694656488"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlist = sorted(scores)\n",
    "nlist[(len(nlist)-1)//2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5198396946564863"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(nlist)/len(nlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(alpha=0.1, base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1.0, gamma=5, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=10, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0.100000001, reg_lambda=1, scale_pos_weight=1,\n",
       "              subsample=1.0, tree_method=None, validate_parameters=False,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/mnt/c/Users/Jonat/Dropbox/CreateDawg/3SC/scalers_LCS/final_3.pkl']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model,outputify(working_directory+\"finalModel_LCS/final_3.pkl\"))\n",
    "joblib.dump(scalers,outputify(working_directory+\"scalers_LCS/final_3.pkl\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stackedTbl  = []\n",
    "results     = list(fOD_2['res'])\n",
    "gameNumbers = sorted(list(set(list(fPM_2['gamenum']))))\n",
    "\n",
    "modelObj    = joblib.load(\"objectiveModels_LCK/obj_2.pkl\")\n",
    "scalerObj   = joblib.load(\"scalers_LCK/sObj_2.pkl\")\n",
    "for game in gameNumbers:\n",
    "    teamR = []\n",
    "    teamB = []\n",
    "    gameDataPVP = fPM_2[fPM_2['gamenum']==game].copy()\n",
    "    gameDataObj = fOD_2[fOD_2['gamenum']==game].copy()\n",
    "    for pos in positions:\n",
    "        relevantD = gameDataPVP[gameDataPVP['position']==pos].copy()\n",
    "        relevantD.drop(['res','position','gamenum'],inplace=True,axis=1)\n",
    "        \n",
    "        relevantM = joblib.load(\"pvpModels_LCK/\"+pos+\"_2.pkl\")\n",
    "        relevantS = joblib.load(\"scalers_LCK/\"+pos+\"_scaler_2.pkl\")\n",
    "        \n",
    "        scaledRD  = relevantS.transform(relevantD)\n",
    "        pvpProbs  = relevantM.predict_proba(scaledRD)\n",
    "        teamR.append(pvpProbs[0][0])\n",
    "        teamB.append(pvpProbs[0][1])\n",
    "    gameDataObj.drop(['res','gamenum'],inplace=True,axis=1)\n",
    "    scaledObjData = scalerObj.transform(gameDataObj)\n",
    "    objResult = modelObj.predict(scaledObjData)\n",
    "    teamR.append(objResult[0])\n",
    "    teamB.append(results[game-(len(gameNumbers)+2)])\n",
    "    stackedTbl.append(teamR + teamB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
