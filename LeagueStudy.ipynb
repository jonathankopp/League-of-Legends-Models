{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "from matplotlib import pyplot\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from time import localtime\n",
    "from datetime import datetime as dt\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.spatial.distance import cdist\n",
    "from pathlib import Path\n",
    "\n",
    "working_directory     = str(os.getcwd()) + \"/\"\n",
    "# working_directoryPT = str(Path.home()) + \"/\"\n",
    "# wd                  = \"/Users/Jonat/Dropbox/CreateDawg/ImRight/input/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['R_firstbloodkill',\n",
       " 'R_firstbloodvictim',\n",
       " 'R_firstdragon',\n",
       " 'R_infernals',\n",
       " 'R_mountains',\n",
       " 'R_clouds',\n",
       " 'R_oceans',\n",
       " 'R_firstherald',\n",
       " 'R_firstbaron',\n",
       " 'R_firsttower',\n",
       " 'R_firstmidtower',\n",
       " 'R_firsttothreetowers',\n",
       " 'R_dpm',\n",
       " 'R_wpm',\n",
       " 'R_wcpm',\n",
       " 'R_earned_gpm',\n",
       " 'R_cspm',\n",
       " 'R_xpat10',\n",
       " 'R_csat10',\n",
       " 'R_golddiffat10',\n",
       " 'R_xpdiffat10',\n",
       " 'R_csdiffat10',\n",
       " 'R_xpat15',\n",
       " 'R_csat15',\n",
       " 'R_golddiffat15',\n",
       " 'R_xpdiffat15',\n",
       " 'R_csdiffat15',\n",
       " 'R_kd',\n",
       " 'R_apm',\n",
       " 'R_mkoj_pm',\n",
       " 'R_mkej_pm',\n",
       " 'R_dragonsdiff',\n",
       " 'R_elementaldrakesdiff',\n",
       " 'R_eldersdiff',\n",
       " 'R_heraldsdiff',\n",
       " 'R_baronsdiff',\n",
       " 'R_towersdiff',\n",
       " 'R_inhibitorsdiff',\n",
       " 'B_firstbloodkill',\n",
       " 'B_firstbloodvictim',\n",
       " 'B_firstdragon',\n",
       " 'B_infernals',\n",
       " 'B_mountains',\n",
       " 'B_clouds',\n",
       " 'B_oceans',\n",
       " 'B_firstherald',\n",
       " 'B_firstbaron',\n",
       " 'B_firsttower',\n",
       " 'B_firstmidtower',\n",
       " 'B_firsttothreetowers',\n",
       " 'B_dpm',\n",
       " 'B_wpm',\n",
       " 'B_wcpm',\n",
       " 'B_earned_gpm',\n",
       " 'B_cspm',\n",
       " 'B_xpat10',\n",
       " 'B_csat10',\n",
       " 'B_golddiffat10',\n",
       " 'B_xpdiffat10',\n",
       " 'B_csdiffat10',\n",
       " 'B_xpat15',\n",
       " 'B_csat15',\n",
       " 'B_golddiffat15',\n",
       " 'B_xpdiffat15',\n",
       " 'B_csdiffat15',\n",
       " 'B_kd',\n",
       " 'B_apm',\n",
       " 'B_mkoj_pm',\n",
       " 'B_mkej_pm',\n",
       " 'B_dragonsdiff',\n",
       " 'B_elementaldrakesdiff',\n",
       " 'B_eldersdiff',\n",
       " 'B_heraldsdiff',\n",
       " 'B_baronsdiff',\n",
       " 'B_towersdiff',\n",
       " 'B_inhibitorsdiff',\n",
       " 'res']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('preproData.csv')\n",
    "data.drop(['R_damageshare','B_damageshare'],axis=1,inplace=True)\n",
    "# print(data['R_team'])\n",
    "list(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "def hyperTune(model,X_Train,Y_Train,X_Test,Y_Test):\n",
    "    #Hyperparameter find utilizing grid search cross validation \n",
    "    C = [1, 10, 100, 1000]\n",
    "    mItr = [500]\n",
    "    tol = [.001,.01]\n",
    "#     class_weight = [{'Blue':0.5, 'Red':0.5}, {'Blue':0.4, 'Red':0.6}, {'Blue':0.6, 'Red':0.4}, {'Blue':0.7, 'Red':0.3},'none']\n",
    "    solver = ['newton-cg', 'lbfgs','sag','saga']\n",
    "    param_grid = dict(tol=tol,max_iter=mItr, C=C,  solver=solver)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    grid = GridSearchCV(estimator=model,param_grid=param_grid,cv=cv,scoring='roc_auc',verbose=1,n_jobs=-1)\n",
    "    grid_result = grid.fit(X_Train, Y_Train)\n",
    "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "    for mean, stdev, param in zip(means, stds, params):\n",
    "        print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "#     print(\"========================================================\")\n",
    "#     print('Train Score: ', grid_result.best_score_)\n",
    "#     print('Best Train Params: ', grid_result.best_params_)\n",
    "#     # print('Validation score:',grid.score(X_Val,Y_Val))\n",
    "#     print('Test score:',grid.score(X_Test,Y_Test))\n",
    "# #     return grid_result.best_params_\n",
    "    return grid_result.best_params_ , grid.score(X_Test, Y_Test)\n",
    "def hyperTuneXGB(model,X_Train,Y_Train,X_Test,Y_Test):\n",
    "    #Hyperparameter find utilizing grid search cross validation \n",
    "    params = {\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'alpha': [0.0001, 0.05,0.1],\n",
    "        'max_depth': [3, 4, 5]\n",
    "    }\n",
    "#     cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    grid = GridSearchCV(estimator=model,param_grid=params,cv=5,scoring='roc_auc',verbose=1,n_jobs=-1)\n",
    "    grid_result = grid.fit(X_Train, Y_Train)\n",
    "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "    for mean, stdev, param in zip(means, stds, params):\n",
    "        print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    return grid_result.best_params_ , grid.score(X_Test, Y_Test)\n",
    "\n",
    "def hyperTuneMLP(model,X_Train,Y_Train,X_Test,Y_Test):\n",
    "    #Hyperparameter find utilizing grid search cross validation \n",
    "    parameter_space = {\n",
    "    'hidden_layer_sizes': [(72,),(107,),(107,214,107),(107,50,20)],\n",
    "    'activation': ['tanh', 'relu','logistic'],\n",
    "    'solver': ['sgd', 'adam','lbfgs'],\n",
    "    'alpha': [0.0001, 0.05,0.1],\n",
    "    'learning_rate': ['constant','adaptive','invscaling'],\n",
    "    }\n",
    "#     cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    grid = GridSearchCV(estimator=model,param_grid=parameter_space,cv=5,scoring='roc_auc',verbose=1,n_jobs=-1)\n",
    "    grid_result = grid.fit(X_Train, Y_Train)\n",
    "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "    for mean, stdev, param in zip(means, stds, params):\n",
    "        print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "#     print(\"========================================================\")\n",
    "#     print('Train Score: ', grid_result.best_score_)\n",
    "#     print('Best Train Params: ', grid_result.best_params_)\n",
    "#     # print('Validation score:',grid.score(X_Val,Y_Val))\n",
    "#     print('Test score:',grid.score(X_Test,Y_Test))\n",
    "# #     return grid_result.best_params_\n",
    "    return grid_result.best_params_ , grid.score(X_Test, Y_Test)\n",
    "def gnb(X_Train,Y_Train,X_Test,Y_Test):\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    clf    = GaussianNB()\n",
    "    clf.fit(X_Train,Y_Train)\n",
    "    y_pred = clf.predict(X_Test)\n",
    "    acc    = accuracy_score(Y_Test,y_pred)\n",
    "    return clf, acc\n",
    "def mlp(X_Train,Y_Train,X_Test,Y_Test):\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    from sklearn.metrics import accuracy_score\n",
    "#     {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (72,), 'learning_rate': 'invscaling', 'solver': 'adam'}\n",
    "#   {'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (107, 214, 107), 'learning_rate': 'adaptive', 'solver': 'adam'}\n",
    "    clf = MLPClassifier(max_iter=10000,activation= 'tanh', alpha= 0.0001,tol=.001, hidden_layer_sizes= (107, 214, 107), learning_rate= 'adaptive', solver= 'adam')\n",
    "    clf.fit(X_Train,Y_Train)\n",
    "    y_pred = clf.predict(X_Test)\n",
    "    acc    = accuracy_score(Y_Test,y_pred)\n",
    "    return clf, acc\n",
    "#     clf = MLPClassifier(max_iter=1)\n",
    "\n",
    "#     hyperparams, bestScore = hyperTuneMLP(clf,X_Train,Y_Train,X_Test,Y_Test)\n",
    "#     return hyperparams, bestScore\n",
    "    \n",
    "def rforest(X_Train,Y_Train,X_Test,Y_Test):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "    clf.fit(X_Train,Y_Train)\n",
    "    y_pred = clf.predict(X_Test)\n",
    "    acc    = accuracy_score(Y_Test,y_pred)\n",
    "    return clf, acc\n",
    "def boosted(X_Train,Y_Train,X_Test,Y_Test):\n",
    "    from xgboost import XGBClassifier\n",
    "    from sklearn.metrics import accuracy_score\n",
    "#     {'alpha': 0.05, 'colsample_bytree': 1.0, 'gamma': 5, 'max_depth': 3, 'min_child_weight': 10, 'subsample': 1.0}\n",
    "    boost    = XGBClassifier(booster='gbtree',alpha='.05',colsample_bytree =1.0, gamma = 5, max_depth = 3, min_child_weight = 10, subsample= 1.0)\n",
    "    boost.fit(X_Train,Y_Train)\n",
    "    y_pred   = boost.predict(X_Test)\n",
    "    accuracy = accuracy_score(Y_Test,y_pred)\n",
    "    return boost, accuracy\n",
    "#     boost = XGBClassifier()\n",
    "#     hyperparams, bestScore = hyperTuneXGB(boost,X_Train,Y_Train,X_Test,Y_Test)\n",
    "#     return hyperparams, bestScore\n",
    "def logReg(X_Train,Y_Train,X_Test,Y_Test):\n",
    "    logRegg = LogisticRegression()\n",
    "#     {'C': 1000, 'max_iter': 500, 'solver': 'newton-cg', 'tol': 0.001}\n",
    "#    {'C': 1000, 'max_iter': 500, 'solver': 'newton-cg', 'tol': 0.001}\n",
    "#     logRegg = LogisticRegression(class_weight = 'none', max_iter= 10000, tol = 0.001, solver= 'newton-cg')\n",
    "#     logRegg.fit(X_Train,Y_Train)\n",
    "#     # model   = SelectFromModel(logRegg,prefit=True)\n",
    "#     # x_new   = model.transform(X_Train)\n",
    "#     # chopp   = model.get_support()\n",
    "#     # for i in range(len(Headers)):\n",
    "#     # if(chopp[i]==True):\n",
    "#     # # print(Headers[i])\n",
    "#     print(\"G: \"+g+\" Score: \",logRegg.score(X_Test,Y_Test))\n",
    "#     return logRegg, logRegg.score(X_Test,Y_Test)\n",
    "#     print(\"================================================================\")\n",
    "\n",
    "    # feature selection\n",
    "\n",
    "    # get the hyperparameters\n",
    "#     try:\n",
    "#         hyperparams, bestScore = hyperTune(logRegg,X_Train,Y_Train,X_Test,Y_Test)\n",
    "#         return hyperparams, bestScore\n",
    "#     except ValueError:\n",
    "#         print('lolwut')\n",
    "    logRegg = LogisticRegression(C=1000, max_iter= 500, solver= 'newton-cg', tol= 0.001)\n",
    "    logRegg.fit(X_Train,Y_Train)\n",
    "    return logRegg, logRegg.score(X_Test,Y_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_selection import SelectFromModel\n",
    "# from numpy import sort\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# rets = data['res']\n",
    "# data.drop(['res'],axis=1,inplace=True)\n",
    "\n",
    "# featSel = VarianceThreshold(.8 * (1 - .8))\n",
    "# featSel.fit(data.copy())\n",
    "# dataCom = data.copy()[data.columns[featSel.get_support(indices=True)]]\n",
    "# dataCom['res'] = rets\n",
    "\n",
    "# print(data.shape,dataCom.shape,\"\\n\",list( set(list(data.columns)) - set(list(dataCom.columns))  ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12838, 76) (12838,) (3210, 76) (3210,)\n",
      "(LogisticRegression(C=1000, max_iter=500, solver='newton-cg', tol=0.001), 0.6056074766355141)\n",
      "0.5984423676012461\n"
     ]
    }
   ],
   "source": [
    "from numpy import sort\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "train, test = train_test_split(data.copy(),test_size=.2)\n",
    "# test, val   = train_test_split(test.copy(),test_size=.5)\n",
    "y_train     = train['res']\n",
    "y_test      = test['res']\n",
    "# y_val       = val['res']\n",
    "train.drop(['res'],axis=1,inplace=True)\n",
    "test.drop(['res'],axis=1,inplace=True)\n",
    "# val.drop(['res'],axis=1,inplace=True)\n",
    "thold = train.copy()\n",
    "\n",
    "scalers = Normalizer()\n",
    "train   = scalers.fit_transform(train)\n",
    "test    = scalers.transform(test)\n",
    "# val     = scalers.transform(val)\n",
    "print(train.shape,y_train.shape,test.shape,y_test.shape)\n",
    "\n",
    "print(logReg(train,y_train,test,y_test))\n",
    "\n",
    "# print(mlp(train,y_train,test,y_test))\n",
    "model = boosted(train,y_train,test,y_test)[0]\n",
    "thresholds = sort(model.feature_importances_)\n",
    "print(boosted(train,y_train,test,y_test)[1])\n",
    "# for thresh in thresholds:\n",
    "#     # select features using threshold\n",
    "#     selection = SelectFromModel(model, threshold=thresh, prefit=True)\n",
    "#     select_X_train = selection.transform(train)\n",
    "#     # train model\n",
    "#     selection_model = XGBClassifier(booster='gbtree',learning_rate=0.1,\n",
    "#        max_delta_step=0, max_depth=3, \n",
    "#        objective='binary:logistic', silent=True)\n",
    "#     selection_model.fit(select_X_train, y_train)\n",
    "#     # eval model\n",
    "#     select_X_test = selection.transform(test)\n",
    "#     predictions = selection_model.predict(select_X_test)\n",
    "#     accuracy = accuracy_score(y_test, predictions)\n",
    "#     print(\"Thresh=%.3f, n=%d, Accuracy: %.2f%%\" % (thresh, select_X_train.shape[1], accuracy*100.0))\n",
    "#     print(rforest(train,y_train,test,y_test)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f56309161264a3da00ae4f936786ae7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %matplotlib inline\n",
    "\n",
    "\n",
    "# labels = list(data.columns[:len(list(data.columns))-1])\n",
    "# x_values = np.arange(1, len(labels) + 1, 1)\n",
    "# plt.bar([i for i in range(len(labels))],model.feature_importances_)\n",
    "\n",
    "# plt.xticks(x_values,labels)\n",
    "\n",
    "# # load data\n",
    "# # plot feature importance\n",
    "# # plot_importance(model)\n",
    "# plt.show()\n",
    "\n",
    "plot_importance(model)\n",
    "plt.show()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(thold.columns[:len(list(thold.columns))-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresh=0.000, n=76, Accuracy: 60.62%\n",
      "Thresh=0.000, n=76, Accuracy: 60.62%\n",
      "Thresh=0.000, n=76, Accuracy: 60.62%\n",
      "Thresh=0.000, n=76, Accuracy: 60.62%\n",
      "Thresh=0.000, n=76, Accuracy: 60.62%\n",
      "Thresh=0.000, n=76, Accuracy: 60.62%\n",
      "Thresh=0.000, n=76, Accuracy: 60.62%\n",
      "Thresh=0.007, n=69, Accuracy: 60.62%\n",
      "Thresh=0.007, n=68, Accuracy: 61.03%\n",
      "Thresh=0.007, n=67, Accuracy: 60.59%\n",
      "Thresh=0.007, n=66, Accuracy: 60.62%\n",
      "Thresh=0.007, n=65, Accuracy: 60.37%\n",
      "Thresh=0.008, n=64, Accuracy: 60.09%\n",
      "Thresh=0.008, n=63, Accuracy: 60.31%\n",
      "Thresh=0.008, n=62, Accuracy: 60.97%\n",
      "Thresh=0.008, n=61, Accuracy: 60.28%\n",
      "Thresh=0.008, n=60, Accuracy: 60.00%\n",
      "Thresh=0.009, n=59, Accuracy: 60.31%\n",
      "Thresh=0.009, n=58, Accuracy: 60.62%\n",
      "Thresh=0.009, n=57, Accuracy: 60.84%\n",
      "Thresh=0.009, n=56, Accuracy: 60.28%\n",
      "Thresh=0.009, n=55, Accuracy: 60.31%\n",
      "Thresh=0.009, n=54, Accuracy: 60.25%\n",
      "Thresh=0.009, n=53, Accuracy: 60.31%\n",
      "Thresh=0.010, n=52, Accuracy: 59.97%\n",
      "Thresh=0.010, n=51, Accuracy: 60.47%\n",
      "Thresh=0.010, n=50, Accuracy: 60.90%\n",
      "Thresh=0.010, n=49, Accuracy: 60.44%\n",
      "Thresh=0.010, n=48, Accuracy: 60.81%\n",
      "Thresh=0.010, n=47, Accuracy: 60.16%\n",
      "Thresh=0.010, n=46, Accuracy: 60.50%\n",
      "Thresh=0.010, n=45, Accuracy: 60.47%\n",
      "Thresh=0.010, n=44, Accuracy: 60.59%\n",
      "Thresh=0.010, n=43, Accuracy: 60.34%\n",
      "Thresh=0.010, n=42, Accuracy: 61.06%\n",
      "Thresh=0.010, n=41, Accuracy: 60.69%\n",
      "Thresh=0.011, n=40, Accuracy: 60.75%\n",
      "Thresh=0.011, n=39, Accuracy: 60.65%\n",
      "Thresh=0.011, n=38, Accuracy: 60.93%\n",
      "Thresh=0.011, n=37, Accuracy: 61.25%\n",
      "Thresh=0.011, n=36, Accuracy: 60.90%\n",
      "Thresh=0.011, n=35, Accuracy: 60.93%\n",
      "Thresh=0.011, n=34, Accuracy: 60.90%\n",
      "Thresh=0.011, n=33, Accuracy: 60.81%\n",
      "Thresh=0.011, n=32, Accuracy: 61.12%\n",
      "Thresh=0.012, n=31, Accuracy: 60.72%\n",
      "Thresh=0.012, n=30, Accuracy: 61.18%\n",
      "Thresh=0.012, n=29, Accuracy: 60.81%\n",
      "Thresh=0.012, n=28, Accuracy: 60.78%\n",
      "Thresh=0.012, n=27, Accuracy: 60.62%\n",
      "Thresh=0.012, n=26, Accuracy: 60.50%\n",
      "Thresh=0.012, n=25, Accuracy: 60.62%\n",
      "Thresh=0.013, n=24, Accuracy: 60.72%\n",
      "Thresh=0.013, n=23, Accuracy: 60.81%\n",
      "Thresh=0.013, n=22, Accuracy: 60.19%\n",
      "Thresh=0.013, n=21, Accuracy: 59.91%\n",
      "Thresh=0.013, n=20, Accuracy: 60.44%\n",
      "Thresh=0.013, n=19, Accuracy: 60.37%\n",
      "Thresh=0.013, n=18, Accuracy: 60.00%\n",
      "Thresh=0.014, n=17, Accuracy: 59.94%\n",
      "Thresh=0.014, n=16, Accuracy: 60.22%\n",
      "Thresh=0.014, n=15, Accuracy: 60.56%\n",
      "Thresh=0.014, n=14, Accuracy: 60.78%\n",
      "Thresh=0.015, n=13, Accuracy: 60.53%\n",
      "Thresh=0.016, n=12, Accuracy: 60.81%\n",
      "Thresh=0.016, n=11, Accuracy: 60.75%\n",
      "Thresh=0.016, n=10, Accuracy: 60.50%\n",
      "Thresh=0.018, n=9, Accuracy: 60.50%\n",
      "Thresh=0.019, n=8, Accuracy: 60.62%\n",
      "Thresh=0.021, n=7, Accuracy: 60.40%\n",
      "Thresh=0.021, n=6, Accuracy: 60.34%\n",
      "Thresh=0.028, n=5, Accuracy: 60.28%\n",
      "Thresh=0.041, n=4, Accuracy: 60.00%\n",
      "Thresh=0.047, n=3, Accuracy: 60.16%\n",
      "Thresh=0.066, n=2, Accuracy: 60.65%\n",
      "Thresh=0.082, n=1, Accuracy: 59.10%\n"
     ]
    }
   ],
   "source": [
    "for thresh in thresholds:\n",
    "    # select features using threshold\n",
    "    selection = SelectFromModel(model, threshold=thresh, prefit=True)\n",
    "    select_X_train = selection.transform(train)\n",
    "    # train model\n",
    "    selection_model = XGBClassifier(booster='gbtree',learning_rate=0.1,\n",
    "       max_delta_step=0, max_depth=3, \n",
    "       objective='binary:logistic', silent=True)\n",
    "    selection_model.fit(select_X_train, y_train)\n",
    "    # eval model\n",
    "    select_X_test = selection.transform(test)\n",
    "    predictions = selection_model.predict(select_X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"Thresh=%.3f, n=%d, Accuracy: %.2f%%\" % (thresh, select_X_train.shape[1], accuracy*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.0068043 , 0.00703641, 0.00724811,\n",
       "       0.00725691, 0.00736302, 0.00757408, 0.00778333, 0.00783229,\n",
       "       0.00841244, 0.00843747, 0.00922668, 0.00928392, 0.00932454,\n",
       "       0.00940478, 0.00945318, 0.00948958, 0.00949016, 0.00960789,\n",
       "       0.00982222, 0.00983732, 0.01000703, 0.01003615, 0.01013857,\n",
       "       0.01015199, 0.01041356, 0.01041844, 0.01042083, 0.01044943,\n",
       "       0.01048137, 0.01063279, 0.01066931, 0.01074408, 0.01089811,\n",
       "       0.01094118, 0.01104471, 0.01122782, 0.01142692, 0.01143759,\n",
       "       0.01174633, 0.01189851, 0.01195469, 0.01209464, 0.01220443,\n",
       "       0.01224677, 0.01227956, 0.01253001, 0.01271537, 0.01288886,\n",
       "       0.01295632, 0.01297239, 0.01314427, 0.01330674, 0.01358879,\n",
       "       0.01368987, 0.01381132, 0.01427826, 0.01528156, 0.01571329,\n",
       "       0.01640091, 0.01646301, 0.01798547, 0.01857896, 0.0209488 ,\n",
       "       0.02132123, 0.02849793, 0.04146114, 0.04678089, 0.06633266,\n",
       "       0.08169846], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
